{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8SUZVldLX9w1JKmRpHNtA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elizabethzhu1/nanogpt-poetry-finetune/blob/main/poetry_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvUSGYjuFu6Y",
        "outputId": "c9259968-ede0-4b5b-9367-262288f42c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karpathy/nanoGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnWKBmi-F-V7",
        "outputId": "72dd353e-6437-436d-aa4b-5d1b1596e1c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nanoGPT'...\n",
            "remote: Enumerating objects: 649, done.\u001b[K\n",
            "remote: Total 649 (delta 0), reused 0 (delta 0), pack-reused 649\u001b[K\n",
            "Receiving objects: 100% (649/649), 935.48 KiB | 12.99 MiB/s, done.\n",
            "Resolving deltas: 100% (373/373), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd nanoGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVG9yXREHMiT",
        "outputId": "04cd4348-56bc-4bf2-ec87-b0f87cca4f07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nanoGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/nanoGPT /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "WBHEA_cdHV-E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-apt-0_wIFR5",
        "outputId": "695e56ba-463f-440d-b1a0-38f7a8831341"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAz2hgtKIPeD",
        "outputId": "fdaf77e6-7755-48a0-bb63-b07023ec96d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, pyarrow-hotfix, docker-pycreds, dill, tiktoken, multiprocess, gitdb, GitPython, wandb, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.40 datasets-2.15.0 dill-0.3.7 docker-pycreds-0.4.0 gitdb-4.0.11 multiprocess-0.70.15 pyarrow-hotfix-0.6 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 tiktoken-0.5.2 wandb-0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ldconfig /usr/lib64-nvidia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH_cDGbJIUd-",
        "outputId": "ad81edb7-4895-4b3d-e6d4-b1d86400e325"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data/poetry/prepare.py"
      ],
      "metadata": {
        "id": "uENDHbX8IaQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py config/train_poetry.py --batch_size=32 --compile=False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJOvx3TUdqmE",
        "outputId": "ef18dd71-1ef0-46fa-f1c7-5c715c868ee1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding config with config/train_poetry.py:\n",
            "# train a miniature character-level shakespeare model\n",
            "# good for debugging and playing on macbooks and such\n",
            "\n",
            "out_dir = 'out-poetry'\n",
            "eval_interval = 250 # keep frequent because we'll overfit\n",
            "eval_iters = 200\n",
            "log_interval = 10 # don't print too too often\n",
            "\n",
            "# we expect to overfit on this small dataset, so only save when val improves\n",
            "always_save_checkpoint = False\n",
            "\n",
            "wandb_log = False # override via command line if you like\n",
            "wandb_project = 'poetry'\n",
            "wandb_run_name = 'mini-gpt'\n",
            "\n",
            "dataset = 'poetry'\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256 # context of up to 256 previous characters\n",
            "\n",
            "# baby GPT model :)\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 384\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
            "max_iters = 5000\n",
            "lr_decay_iters = 5000 # make equal to max_iters usually\n",
            "min_lr = 1e-4 # learning_rate / 10 usually\n",
            "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
            "\n",
            "warmup_iters = 100 # not super necessary potentially\n",
            "\n",
            "# on macbook also add\n",
            "# device = 'cpu'  # run on cpu only\n",
            "# compile = False # do not torch compile the model\n",
            "\n",
            "Overriding: batch_size = 32\n",
            "Overriding: compile = False\n",
            "tokens per iteration will be: 8,192\n",
            "Initializing a new model from scratch\n",
            "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)\n",
            "number of parameters: 29.94M\n",
            "num decayed parameter tensors: 26, with 30,031,872 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 10.9019, val loss 10.9002\n",
            "iter 0: loss 10.8994, time 21505.18ms, mfu -100.00%\n",
            "iter 10: loss 9.8224, time 162.40ms, mfu 3.02%\n",
            "iter 20: loss 9.2913, time 162.63ms, mfu 3.02%\n",
            "iter 30: loss 7.9856, time 162.85ms, mfu 3.02%\n",
            "iter 40: loss 7.0401, time 164.12ms, mfu 3.01%\n",
            "iter 50: loss 6.6518, time 164.26ms, mfu 3.01%\n",
            "iter 60: loss 6.4465, time 166.74ms, mfu 3.00%\n",
            "iter 70: loss 6.3105, time 165.36ms, mfu 3.00%\n",
            "iter 80: loss 6.1887, time 163.78ms, mfu 3.00%\n",
            "iter 90: loss 6.0151, time 163.90ms, mfu 3.00%\n",
            "iter 100: loss 5.9366, time 166.37ms, mfu 2.99%\n",
            "iter 110: loss 5.8144, time 164.93ms, mfu 2.99%\n",
            "iter 120: loss 5.6550, time 165.71ms, mfu 2.99%\n",
            "iter 130: loss 5.7809, time 165.34ms, mfu 2.99%\n",
            "iter 140: loss 5.6108, time 166.61ms, mfu 2.98%\n",
            "iter 150: loss 5.5239, time 168.29ms, mfu 2.97%\n",
            "iter 160: loss 5.2796, time 164.71ms, mfu 2.97%\n",
            "iter 170: loss 5.3413, time 170.28ms, mfu 2.97%\n",
            "iter 180: loss 5.4070, time 168.77ms, mfu 2.96%\n",
            "iter 190: loss 5.3465, time 169.74ms, mfu 2.95%\n",
            "iter 200: loss 5.4056, time 168.73ms, mfu 2.95%\n",
            "iter 210: loss 5.1733, time 169.67ms, mfu 2.94%\n",
            "iter 220: loss 5.2316, time 169.60ms, mfu 2.94%\n",
            "iter 230: loss 5.1021, time 171.47ms, mfu 2.93%\n",
            "iter 240: loss 5.0365, time 170.39ms, mfu 2.92%\n",
            "step 250: train loss 5.0195, val loss 6.0409\n",
            "saving checkpoint to out-poetry\n",
            "iter 250: loss 5.0400, time 23784.88ms, mfu 2.63%\n",
            "iter 260: loss 5.1433, time 175.12ms, mfu 2.65%\n",
            "iter 270: loss 5.0460, time 175.03ms, mfu 2.66%\n",
            "iter 280: loss 4.8787, time 175.34ms, mfu 2.68%\n",
            "iter 290: loss 5.0281, time 177.75ms, mfu 2.69%\n",
            "iter 300: loss 4.8817, time 176.37ms, mfu 2.70%\n",
            "iter 310: loss 4.8672, time 176.88ms, mfu 2.70%\n",
            "iter 320: loss 4.8626, time 177.07ms, mfu 2.71%\n",
            "iter 330: loss 4.7435, time 179.49ms, mfu 2.71%\n",
            "iter 340: loss 4.6892, time 178.60ms, mfu 2.72%\n",
            "iter 350: loss 4.7140, time 180.89ms, mfu 2.71%\n",
            "iter 360: loss 4.6459, time 182.74ms, mfu 2.71%\n",
            "iter 370: loss 4.6670, time 180.82ms, mfu 2.71%\n",
            "iter 380: loss 4.5142, time 182.93ms, mfu 2.71%\n",
            "iter 390: loss 4.5342, time 183.51ms, mfu 2.70%\n",
            "iter 400: loss 4.5289, time 183.31ms, mfu 2.70%\n",
            "iter 410: loss 4.4954, time 183.47ms, mfu 2.70%\n",
            "iter 420: loss 4.4453, time 184.10ms, mfu 2.69%\n",
            "iter 430: loss 4.3524, time 183.35ms, mfu 2.69%\n",
            "iter 440: loss 4.3686, time 187.85ms, mfu 2.68%\n",
            "iter 450: loss 4.2968, time 185.50ms, mfu 2.68%\n",
            "iter 460: loss 4.2188, time 183.49ms, mfu 2.68%\n",
            "iter 470: loss 4.1867, time 184.09ms, mfu 2.68%\n",
            "iter 480: loss 4.1016, time 186.92ms, mfu 2.67%\n",
            "iter 490: loss 4.0567, time 186.71ms, mfu 2.67%\n",
            "step 500: train loss 3.9656, val loss 6.4307\n",
            "iter 500: loss 4.1597, time 24515.16ms, mfu 2.40%\n",
            "iter 510: loss 4.0916, time 178.38ms, mfu 2.44%\n",
            "iter 520: loss 4.0902, time 177.95ms, mfu 2.47%\n",
            "iter 530: loss 4.1096, time 180.23ms, mfu 2.49%\n",
            "iter 540: loss 3.7998, time 178.57ms, mfu 2.52%\n",
            "iter 550: loss 3.9895, time 177.21ms, mfu 2.54%\n",
            "iter 560: loss 3.9947, time 178.38ms, mfu 2.56%\n",
            "iter 570: loss 3.8189, time 177.80ms, mfu 2.58%\n",
            "iter 580: loss 3.8422, time 177.74ms, mfu 2.60%\n",
            "iter 590: loss 3.7823, time 177.43ms, mfu 2.62%\n",
            "iter 600: loss 3.8952, time 177.32ms, mfu 2.63%\n",
            "iter 610: loss 3.7648, time 179.36ms, mfu 2.64%\n",
            "iter 620: loss 3.4978, time 177.33ms, mfu 2.65%\n",
            "iter 630: loss 3.7194, time 177.73ms, mfu 2.66%\n",
            "iter 640: loss 3.7151, time 179.25ms, mfu 2.67%\n",
            "iter 650: loss 3.4977, time 179.23ms, mfu 2.68%\n",
            "iter 660: loss 3.7098, time 180.93ms, mfu 2.68%\n",
            "iter 670: loss 3.4788, time 177.88ms, mfu 2.69%\n",
            "iter 680: loss 3.5219, time 179.67ms, mfu 2.69%\n",
            "iter 690: loss 3.4230, time 178.60ms, mfu 2.70%\n",
            "iter 700: loss 3.4321, time 178.60ms, mfu 2.70%\n",
            "iter 710: loss 3.2644, time 180.43ms, mfu 2.70%\n",
            "iter 720: loss 3.2859, time 178.47ms, mfu 2.71%\n",
            "iter 730: loss 3.2136, time 178.99ms, mfu 2.71%\n",
            "iter 740: loss 3.2080, time 178.92ms, mfu 2.71%\n",
            "step 750: train loss 2.8561, val loss 6.9726\n",
            "iter 750: loss 3.2203, time 24489.00ms, mfu 2.44%\n",
            "iter 760: loss 3.3947, time 181.76ms, mfu 2.47%\n",
            "iter 770: loss 3.0338, time 180.10ms, mfu 2.50%\n",
            "iter 780: loss 3.0748, time 181.58ms, mfu 2.52%\n",
            "iter 790: loss 3.0501, time 180.45ms, mfu 2.54%\n",
            "iter 800: loss 2.9533, time 182.32ms, mfu 2.55%\n",
            "iter 810: loss 2.9848, time 178.90ms, mfu 2.57%\n",
            "iter 820: loss 3.0256, time 177.60ms, mfu 2.59%\n",
            "iter 830: loss 2.8471, time 179.88ms, mfu 2.60%\n",
            "iter 840: loss 2.9368, time 180.36ms, mfu 2.61%\n",
            "iter 850: loss 2.9686, time 178.86ms, mfu 2.63%\n",
            "iter 860: loss 2.7505, time 179.77ms, mfu 2.64%\n",
            "iter 870: loss 2.7451, time 179.60ms, mfu 2.65%\n",
            "iter 880: loss 2.9598, time 178.00ms, mfu 2.66%\n",
            "iter 890: loss 2.7488, time 177.53ms, mfu 2.67%\n",
            "iter 900: loss 2.7248, time 178.96ms, mfu 2.67%\n",
            "iter 910: loss 2.5060, time 177.70ms, mfu 2.68%\n",
            "iter 920: loss 2.6316, time 180.10ms, mfu 2.69%\n",
            "iter 930: loss 2.6014, time 178.01ms, mfu 2.69%\n",
            "iter 940: loss 2.3943, time 177.75ms, mfu 2.70%\n",
            "iter 950: loss 2.6172, time 178.75ms, mfu 2.70%\n",
            "iter 960: loss 2.4291, time 177.81ms, mfu 2.71%\n",
            "iter 970: loss 2.3924, time 178.84ms, mfu 2.71%\n",
            "iter 980: loss 2.4075, time 178.64ms, mfu 2.72%\n",
            "iter 990: loss 2.3277, time 177.19ms, mfu 2.72%\n",
            "step 1000: train loss 1.8261, val loss 7.7511\n",
            "iter 1000: loss 2.2403, time 24496.59ms, mfu 2.45%\n",
            "iter 1010: loss 2.1848, time 179.63ms, mfu 2.48%\n",
            "iter 1020: loss 2.3132, time 179.33ms, mfu 2.50%\n",
            "iter 1030: loss 2.2584, time 178.52ms, mfu 2.53%\n",
            "iter 1040: loss 2.0534, time 176.41ms, mfu 2.55%\n",
            "iter 1050: loss 2.1474, time 178.38ms, mfu 2.57%\n",
            "iter 1060: loss 2.1168, time 177.67ms, mfu 2.59%\n",
            "iter 1070: loss 2.1202, time 178.85ms, mfu 2.61%\n",
            "iter 1080: loss 2.1146, time 176.55ms, mfu 2.62%\n",
            "iter 1090: loss 2.0867, time 177.83ms, mfu 2.64%\n",
            "iter 1100: loss 2.1444, time 177.24ms, mfu 2.65%\n",
            "iter 1110: loss 2.0167, time 178.20ms, mfu 2.66%\n",
            "iter 1120: loss 2.0799, time 178.18ms, mfu 2.67%\n",
            "iter 1130: loss 2.0358, time 177.40ms, mfu 2.68%\n",
            "iter 1140: loss 1.8846, time 175.98ms, mfu 2.69%\n",
            "iter 1150: loss 1.9786, time 179.45ms, mfu 2.69%\n",
            "iter 1160: loss 1.9161, time 176.97ms, mfu 2.70%\n",
            "iter 1170: loss 1.7994, time 176.34ms, mfu 2.71%\n",
            "iter 1180: loss 1.8610, time 177.79ms, mfu 2.71%\n",
            "iter 1190: loss 1.9421, time 177.89ms, mfu 2.72%\n",
            "iter 1200: loss 1.7544, time 177.28ms, mfu 2.72%\n",
            "iter 1210: loss 1.7433, time 177.00ms, mfu 2.73%\n",
            "iter 1220: loss 1.9016, time 178.87ms, mfu 2.73%\n",
            "iter 1230: loss 1.6853, time 179.78ms, mfu 2.73%\n",
            "iter 1240: loss 1.7980, time 180.52ms, mfu 2.73%\n",
            "step 1250: train loss 1.1116, val loss 8.4167\n",
            "iter 1250: loss 1.7408, time 24493.42ms, mfu 2.46%\n",
            "iter 1260: loss 1.6116, time 178.38ms, mfu 2.49%\n",
            "iter 1270: loss 1.6476, time 179.02ms, mfu 2.51%\n",
            "iter 1280: loss 1.6096, time 179.05ms, mfu 2.53%\n",
            "iter 1290: loss 1.5818, time 179.28ms, mfu 2.55%\n",
            "iter 1300: loss 1.5968, time 178.17ms, mfu 2.57%\n",
            "iter 1310: loss 1.7414, time 178.97ms, mfu 2.59%\n",
            "iter 1320: loss 1.7566, time 178.22ms, mfu 2.61%\n",
            "iter 1330: loss 1.5009, time 178.87ms, mfu 2.62%\n",
            "iter 1340: loss 1.6136, time 179.31ms, mfu 2.63%\n",
            "iter 1350: loss 1.5401, time 177.68ms, mfu 2.64%\n",
            "iter 1360: loss 1.3944, time 177.68ms, mfu 2.66%\n",
            "iter 1370: loss 1.5421, time 176.05ms, mfu 2.67%\n",
            "iter 1380: loss 1.4683, time 177.10ms, mfu 2.68%\n",
            "iter 1390: loss 1.4179, time 177.88ms, mfu 2.69%\n",
            "iter 1400: loss 1.5225, time 177.32ms, mfu 2.69%\n",
            "iter 1410: loss 1.3677, time 177.74ms, mfu 2.70%\n",
            "iter 1420: loss 1.3805, time 177.95ms, mfu 2.71%\n",
            "iter 1430: loss 1.5341, time 175.97ms, mfu 2.71%\n",
            "iter 1440: loss 1.4343, time 176.79ms, mfu 2.72%\n",
            "iter 1450: loss 1.2574, time 175.58ms, mfu 2.73%\n",
            "iter 1460: loss 1.4583, time 177.95ms, mfu 2.73%\n",
            "iter 1470: loss 1.3613, time 177.91ms, mfu 2.73%\n",
            "iter 1480: loss 1.2801, time 176.70ms, mfu 2.74%\n",
            "iter 1490: loss 1.3469, time 177.65ms, mfu 2.74%\n",
            "step 1500: train loss 0.7051, val loss 9.0611\n",
            "iter 1500: loss 1.2199, time 24478.39ms, mfu 2.47%\n",
            "iter 1510: loss 1.2049, time 178.14ms, mfu 2.50%\n",
            "iter 1520: loss 1.2542, time 176.59ms, mfu 2.52%\n",
            "iter 1530: loss 1.1821, time 177.56ms, mfu 2.55%\n",
            "iter 1540: loss 1.1828, time 177.00ms, mfu 2.57%\n",
            "iter 1550: loss 1.2175, time 176.28ms, mfu 2.59%\n",
            "iter 1560: loss 1.3472, time 177.79ms, mfu 2.61%\n",
            "iter 1570: loss 1.1058, time 176.96ms, mfu 2.62%\n",
            "iter 1580: loss 1.2282, time 176.14ms, mfu 2.64%\n",
            "iter 1590: loss 1.2092, time 176.24ms, mfu 2.65%\n",
            "iter 1600: loss 1.1523, time 176.34ms, mfu 2.67%\n",
            "iter 1610: loss 1.2284, time 177.29ms, mfu 2.68%\n",
            "iter 1620: loss 1.2140, time 175.61ms, mfu 2.69%\n",
            "iter 1630: loss 1.1188, time 177.76ms, mfu 2.69%\n",
            "iter 1640: loss 1.2755, time 178.58ms, mfu 2.70%\n",
            "iter 1650: loss 1.1695, time 176.12ms, mfu 2.71%\n",
            "iter 1660: loss 1.1556, time 178.08ms, mfu 2.71%\n",
            "iter 1670: loss 1.1214, time 175.93ms, mfu 2.72%\n",
            "iter 1680: loss 1.1329, time 178.36ms, mfu 2.72%\n",
            "iter 1690: loss 1.0541, time 175.97ms, mfu 2.73%\n",
            "iter 1700: loss 1.0096, time 176.78ms, mfu 2.73%\n",
            "iter 1710: loss 0.9242, time 173.67ms, mfu 2.74%\n",
            "iter 1720: loss 1.1383, time 177.02ms, mfu 2.75%\n",
            "iter 1730: loss 1.0312, time 177.68ms, mfu 2.75%\n",
            "iter 1740: loss 1.0101, time 177.09ms, mfu 2.75%\n",
            "step 1750: train loss 0.4861, val loss 9.5970\n",
            "iter 1750: loss 1.0865, time 24494.82ms, mfu 2.48%\n",
            "iter 1760: loss 1.0681, time 175.38ms, mfu 2.51%\n",
            "iter 1770: loss 1.0906, time 175.68ms, mfu 2.54%\n",
            "iter 1780: loss 0.9902, time 177.66ms, mfu 2.56%\n",
            "iter 1790: loss 0.9780, time 177.20ms, mfu 2.58%\n",
            "iter 1800: loss 0.9758, time 176.95ms, mfu 2.60%\n",
            "iter 1810: loss 0.9646, time 177.18ms, mfu 2.62%\n",
            "iter 1820: loss 0.9581, time 175.53ms, mfu 2.63%\n",
            "iter 1830: loss 0.9842, time 176.91ms, mfu 2.65%\n",
            "iter 1840: loss 0.9549, time 176.34ms, mfu 2.66%\n",
            "iter 1850: loss 0.9654, time 175.50ms, mfu 2.67%\n",
            "iter 1860: loss 0.8826, time 175.95ms, mfu 2.68%\n",
            "iter 1870: loss 0.8995, time 176.55ms, mfu 2.69%\n",
            "iter 1880: loss 0.9285, time 177.56ms, mfu 2.70%\n",
            "iter 1890: loss 0.9829, time 176.77ms, mfu 2.71%\n",
            "iter 1900: loss 0.8985, time 176.75ms, mfu 2.71%\n",
            "iter 1910: loss 0.9700, time 177.36ms, mfu 2.72%\n",
            "iter 1920: loss 0.9284, time 176.53ms, mfu 2.73%\n",
            "iter 1930: loss 0.9403, time 176.17ms, mfu 2.73%\n",
            "iter 1940: loss 0.9348, time 175.82ms, mfu 2.74%\n",
            "iter 1950: loss 0.8761, time 177.41ms, mfu 2.74%\n",
            "iter 1960: loss 0.9191, time 175.86ms, mfu 2.74%\n",
            "iter 1970: loss 0.8855, time 177.76ms, mfu 2.75%\n",
            "iter 1980: loss 0.8607, time 176.28ms, mfu 2.75%\n",
            "iter 1990: loss 0.8471, time 176.83ms, mfu 2.75%\n",
            "step 2000: train loss 0.3709, val loss 9.9878\n",
            "iter 2000: loss 0.7945, time 24493.81ms, mfu 2.48%\n",
            "iter 2010: loss 0.9062, time 175.26ms, mfu 2.51%\n",
            "iter 2020: loss 0.8250, time 175.35ms, mfu 2.54%\n",
            "iter 2030: loss 0.8321, time 176.32ms, mfu 2.56%\n",
            "iter 2040: loss 0.7707, time 175.62ms, mfu 2.59%\n",
            "iter 2050: loss 0.8827, time 177.00ms, mfu 2.60%\n",
            "iter 2060: loss 0.8203, time 175.32ms, mfu 2.62%\n",
            "iter 2070: loss 0.8914, time 178.48ms, mfu 2.64%\n",
            "iter 2080: loss 0.9133, time 177.29ms, mfu 2.65%\n",
            "iter 2090: loss 0.8235, time 176.38ms, mfu 2.66%\n",
            "iter 2100: loss 0.7524, time 177.61ms, mfu 2.67%\n",
            "iter 2110: loss 0.8283, time 176.61ms, mfu 2.68%\n",
            "iter 2120: loss 0.7936, time 177.20ms, mfu 2.69%\n",
            "iter 2130: loss 0.7889, time 175.48ms, mfu 2.70%\n",
            "iter 2140: loss 0.6965, time 176.98ms, mfu 2.71%\n",
            "iter 2150: loss 0.8230, time 176.31ms, mfu 2.71%\n",
            "iter 2160: loss 0.7471, time 176.57ms, mfu 2.72%\n",
            "iter 2170: loss 0.7256, time 177.89ms, mfu 2.72%\n",
            "iter 2180: loss 0.7633, time 177.01ms, mfu 2.73%\n",
            "iter 2190: loss 0.7634, time 175.91ms, mfu 2.73%\n",
            "iter 2200: loss 0.7580, time 175.34ms, mfu 2.74%\n",
            "iter 2210: loss 0.8013, time 176.38ms, mfu 2.74%\n",
            "iter 2220: loss 0.7631, time 177.64ms, mfu 2.75%\n",
            "iter 2230: loss 0.7026, time 176.01ms, mfu 2.75%\n",
            "iter 2240: loss 0.7632, time 177.00ms, mfu 2.75%\n",
            "step 2250: train loss 0.2971, val loss 10.3948\n",
            "iter 2250: loss 0.8020, time 24502.10ms, mfu 2.48%\n",
            "iter 2260: loss 0.7067, time 175.77ms, mfu 2.51%\n",
            "iter 2270: loss 0.7172, time 174.89ms, mfu 2.54%\n",
            "iter 2280: loss 0.7282, time 177.68ms, mfu 2.56%\n",
            "iter 2290: loss 0.7026, time 175.91ms, mfu 2.58%\n",
            "iter 2300: loss 0.6839, time 176.41ms, mfu 2.60%\n",
            "iter 2310: loss 0.7340, time 176.43ms, mfu 2.62%\n",
            "iter 2320: loss 0.6687, time 178.00ms, mfu 2.63%\n",
            "iter 2330: loss 0.6803, time 177.12ms, mfu 2.65%\n",
            "iter 2340: loss 0.6412, time 175.47ms, mfu 2.66%\n",
            "iter 2350: loss 0.6598, time 177.85ms, mfu 2.67%\n",
            "iter 2360: loss 0.6541, time 176.49ms, mfu 2.68%\n",
            "iter 2370: loss 0.6317, time 175.46ms, mfu 2.69%\n",
            "iter 2380: loss 0.6819, time 174.81ms, mfu 2.70%\n",
            "iter 2390: loss 0.6411, time 176.60ms, mfu 2.71%\n",
            "iter 2400: loss 0.6661, time 176.07ms, mfu 2.72%\n",
            "iter 2410: loss 0.6415, time 175.41ms, mfu 2.73%\n",
            "iter 2420: loss 0.6722, time 177.71ms, mfu 2.73%\n",
            "iter 2430: loss 0.6584, time 175.47ms, mfu 2.74%\n",
            "iter 2440: loss 0.6683, time 176.99ms, mfu 2.74%\n",
            "iter 2450: loss 0.6477, time 175.34ms, mfu 2.75%\n",
            "iter 2460: loss 0.6546, time 176.56ms, mfu 2.75%\n",
            "iter 2470: loss 0.6693, time 176.22ms, mfu 2.75%\n",
            "iter 2480: loss 0.6562, time 175.31ms, mfu 2.76%\n",
            "iter 2490: loss 0.6217, time 175.51ms, mfu 2.76%\n",
            "step 2500: train loss 0.2456, val loss 10.5848\n",
            "iter 2500: loss 0.5786, time 24497.35ms, mfu 2.49%\n",
            "iter 2510: loss 0.5868, time 176.34ms, mfu 2.52%\n",
            "iter 2520: loss 0.6508, time 176.20ms, mfu 2.54%\n",
            "iter 2530: loss 0.5766, time 176.73ms, mfu 2.57%\n",
            "iter 2540: loss 0.6389, time 178.35ms, mfu 2.58%\n",
            "iter 2550: loss 0.5986, time 176.39ms, mfu 2.60%\n",
            "iter 2560: loss 0.5992, time 175.88ms, mfu 2.62%\n",
            "iter 2570: loss 0.5925, time 175.89ms, mfu 2.64%\n",
            "iter 2580: loss 0.6090, time 174.63ms, mfu 2.65%\n",
            "iter 2590: loss 0.6268, time 178.35ms, mfu 2.66%\n",
            "iter 2600: loss 0.5850, time 176.31ms, mfu 2.68%\n",
            "iter 2610: loss 0.5904, time 176.15ms, mfu 2.69%\n",
            "iter 2620: loss 0.5426, time 176.27ms, mfu 2.70%\n",
            "iter 2630: loss 0.5705, time 176.71ms, mfu 2.70%\n",
            "iter 2640: loss 0.6475, time 177.91ms, mfu 2.71%\n",
            "iter 2650: loss 0.6020, time 176.77ms, mfu 2.72%\n",
            "iter 2660: loss 0.5831, time 175.51ms, mfu 2.72%\n",
            "iter 2670: loss 0.5850, time 178.34ms, mfu 2.73%\n",
            "iter 2680: loss 0.5709, time 175.45ms, mfu 2.73%\n",
            "iter 2690: loss 0.5546, time 175.23ms, mfu 2.74%\n",
            "iter 2700: loss 0.5955, time 175.95ms, mfu 2.74%\n",
            "iter 2710: loss 0.5358, time 178.40ms, mfu 2.74%\n",
            "iter 2720: loss 0.5518, time 175.90ms, mfu 2.75%\n",
            "iter 2730: loss 0.5168, time 176.09ms, mfu 2.75%\n",
            "iter 2740: loss 0.5083, time 176.45ms, mfu 2.75%\n",
            "step 2750: train loss 0.2124, val loss 10.9348\n",
            "iter 2750: loss 0.5432, time 24489.59ms, mfu 2.48%\n",
            "iter 2760: loss 0.5496, time 176.42ms, mfu 2.51%\n",
            "iter 2770: loss 0.5438, time 175.71ms, mfu 2.54%\n",
            "iter 2780: loss 0.5615, time 176.70ms, mfu 2.56%\n",
            "iter 2790: loss 0.5134, time 175.72ms, mfu 2.59%\n",
            "iter 2800: loss 0.5271, time 178.81ms, mfu 2.60%\n",
            "iter 2810: loss 0.5472, time 176.18ms, mfu 2.62%\n",
            "iter 2820: loss 0.5132, time 176.95ms, mfu 2.63%\n",
            "iter 2830: loss 0.5009, time 177.64ms, mfu 2.65%\n",
            "iter 2840: loss 0.5129, time 177.95ms, mfu 2.66%\n",
            "iter 2850: loss 0.5312, time 176.13ms, mfu 2.67%\n",
            "iter 2860: loss 0.5333, time 175.39ms, mfu 2.68%\n",
            "iter 2870: loss 0.5440, time 175.78ms, mfu 2.69%\n",
            "iter 2880: loss 0.4663, time 176.20ms, mfu 2.70%\n",
            "iter 2890: loss 0.4940, time 173.91ms, mfu 2.71%\n",
            "iter 2900: loss 0.4799, time 175.39ms, mfu 2.72%\n",
            "iter 2910: loss 0.5020, time 179.20ms, mfu 2.72%\n",
            "iter 2920: loss 0.4843, time 175.92ms, mfu 2.73%\n",
            "iter 2930: loss 0.4918, time 176.38ms, mfu 2.73%\n",
            "iter 2940: loss 0.5033, time 175.68ms, mfu 2.74%\n",
            "iter 2950: loss 0.5142, time 175.92ms, mfu 2.74%\n",
            "iter 2960: loss 0.4845, time 175.76ms, mfu 2.75%\n",
            "iter 2970: loss 0.5040, time 175.32ms, mfu 2.75%\n",
            "iter 2980: loss 0.4594, time 177.12ms, mfu 2.76%\n",
            "iter 2990: loss 0.4841, time 176.76ms, mfu 2.76%\n",
            "step 3000: train loss 0.1791, val loss 11.1212\n",
            "iter 3000: loss 0.4736, time 24482.95ms, mfu 2.48%\n",
            "iter 3010: loss 0.4692, time 175.92ms, mfu 2.51%\n",
            "iter 3020: loss 0.4638, time 175.17ms, mfu 2.54%\n",
            "iter 3030: loss 0.4894, time 176.18ms, mfu 2.57%\n",
            "iter 3040: loss 0.4865, time 177.27ms, mfu 2.59%\n",
            "iter 3050: loss 0.4883, time 176.37ms, mfu 2.61%\n",
            "iter 3060: loss 0.4408, time 177.48ms, mfu 2.62%\n",
            "iter 3070: loss 0.4424, time 175.57ms, mfu 2.64%\n",
            "iter 3080: loss 0.4272, time 175.61ms, mfu 2.65%\n",
            "iter 3090: loss 0.4603, time 175.28ms, mfu 2.67%\n",
            "iter 3100: loss 0.4636, time 175.37ms, mfu 2.68%\n",
            "iter 3110: loss 0.4171, time 175.62ms, mfu 2.69%\n",
            "iter 3120: loss 0.4313, time 175.02ms, mfu 2.70%\n",
            "iter 3130: loss 0.4586, time 175.78ms, mfu 2.71%\n",
            "iter 3140: loss 0.4471, time 174.75ms, mfu 2.72%\n",
            "iter 3150: loss 0.4492, time 176.59ms, mfu 2.73%\n",
            "iter 3160: loss 0.4465, time 175.90ms, mfu 2.73%\n",
            "iter 3170: loss 0.4110, time 174.55ms, mfu 2.74%\n",
            "iter 3180: loss 0.4335, time 176.28ms, mfu 2.74%\n",
            "iter 3190: loss 0.4301, time 176.20ms, mfu 2.75%\n",
            "iter 3200: loss 0.4185, time 177.50ms, mfu 2.75%\n",
            "iter 3210: loss 0.4198, time 175.92ms, mfu 2.75%\n",
            "iter 3220: loss 0.4263, time 175.57ms, mfu 2.76%\n",
            "iter 3230: loss 0.4015, time 175.55ms, mfu 2.76%\n",
            "iter 3240: loss 0.4318, time 175.97ms, mfu 2.76%\n",
            "step 3250: train loss 0.1567, val loss 11.2161\n",
            "iter 3250: loss 0.4253, time 24487.80ms, mfu 2.49%\n",
            "iter 3260: loss 0.4507, time 176.64ms, mfu 2.52%\n",
            "iter 3270: loss 0.4042, time 177.69ms, mfu 2.54%\n",
            "iter 3280: loss 0.4077, time 175.37ms, mfu 2.57%\n",
            "iter 3290: loss 0.3950, time 175.96ms, mfu 2.59%\n",
            "iter 3300: loss 0.4103, time 177.12ms, mfu 2.61%\n",
            "iter 3310: loss 0.3956, time 178.72ms, mfu 2.62%\n",
            "iter 3320: loss 0.4275, time 176.04ms, mfu 2.64%\n",
            "iter 3330: loss 0.3885, time 175.64ms, mfu 2.65%\n",
            "iter 3340: loss 0.3809, time 176.59ms, mfu 2.66%\n",
            "iter 3350: loss 0.3843, time 174.87ms, mfu 2.68%\n",
            "iter 3360: loss 0.3976, time 177.00ms, mfu 2.69%\n",
            "iter 3370: loss 0.4081, time 177.19ms, mfu 2.70%\n",
            "iter 3380: loss 0.4023, time 176.90ms, mfu 2.70%\n",
            "iter 3390: loss 0.3924, time 177.13ms, mfu 2.71%\n",
            "iter 3400: loss 0.3990, time 175.40ms, mfu 2.72%\n",
            "iter 3410: loss 0.3582, time 175.62ms, mfu 2.73%\n",
            "iter 3420: loss 0.4174, time 176.24ms, mfu 2.73%\n",
            "iter 3430: loss 0.4079, time 176.14ms, mfu 2.74%\n",
            "iter 3440: loss 0.3678, time 175.48ms, mfu 2.74%\n",
            "iter 3450: loss 0.3882, time 175.63ms, mfu 2.75%\n",
            "iter 3460: loss 0.4211, time 175.17ms, mfu 2.75%\n",
            "iter 3470: loss 0.3537, time 176.46ms, mfu 2.75%\n",
            "iter 3480: loss 0.3664, time 176.14ms, mfu 2.76%\n",
            "iter 3490: loss 0.3837, time 175.75ms, mfu 2.76%\n",
            "step 3500: train loss 0.1400, val loss 11.4283\n",
            "iter 3500: loss 0.3746, time 24501.70ms, mfu 2.49%\n",
            "iter 3510: loss 0.3660, time 174.93ms, mfu 2.52%\n",
            "iter 3520: loss 0.3842, time 174.91ms, mfu 2.55%\n",
            "iter 3530: loss 0.3587, time 176.19ms, mfu 2.57%\n",
            "iter 3540: loss 0.3647, time 175.83ms, mfu 2.59%\n",
            "iter 3550: loss 0.3908, time 173.61ms, mfu 2.62%\n",
            "iter 3560: loss 0.3685, time 175.93ms, mfu 2.63%\n",
            "iter 3570: loss 0.3674, time 175.06ms, mfu 2.65%\n",
            "iter 3580: loss 0.3781, time 173.88ms, mfu 2.67%\n",
            "iter 3590: loss 0.3822, time 175.65ms, mfu 2.68%\n",
            "iter 3600: loss 0.3372, time 174.96ms, mfu 2.69%\n",
            "iter 3610: loss 0.3768, time 174.70ms, mfu 2.70%\n",
            "iter 3620: loss 0.3883, time 176.60ms, mfu 2.71%\n",
            "iter 3630: loss 0.3398, time 176.65ms, mfu 2.72%\n",
            "iter 3640: loss 0.3373, time 175.53ms, mfu 2.72%\n",
            "iter 3650: loss 0.3345, time 176.37ms, mfu 2.73%\n",
            "iter 3660: loss 0.4028, time 176.46ms, mfu 2.73%\n",
            "iter 3670: loss 0.3782, time 174.88ms, mfu 2.74%\n",
            "iter 3680: loss 0.3523, time 176.07ms, mfu 2.75%\n",
            "iter 3690: loss 0.3827, time 176.24ms, mfu 2.75%\n",
            "iter 3700: loss 0.3348, time 176.34ms, mfu 2.75%\n",
            "iter 3710: loss 0.3346, time 175.86ms, mfu 2.76%\n",
            "iter 3720: loss 0.3590, time 176.05ms, mfu 2.76%\n",
            "iter 3730: loss 0.3613, time 175.11ms, mfu 2.76%\n",
            "iter 3740: loss 0.3271, time 175.73ms, mfu 2.77%\n",
            "step 3750: train loss 0.1289, val loss 11.4397\n",
            "iter 3750: loss 0.3413, time 24494.32ms, mfu 2.49%\n",
            "iter 3760: loss 0.3369, time 175.02ms, mfu 2.52%\n",
            "iter 3770: loss 0.3481, time 177.10ms, mfu 2.55%\n",
            "iter 3780: loss 0.3619, time 175.21ms, mfu 2.57%\n",
            "iter 3790: loss 0.3314, time 176.62ms, mfu 2.59%\n",
            "iter 3800: loss 0.3304, time 176.88ms, mfu 2.61%\n",
            "iter 3810: loss 0.3266, time 176.19ms, mfu 2.63%\n",
            "iter 3820: loss 0.3129, time 178.06ms, mfu 2.64%\n",
            "iter 3830: loss 0.3547, time 176.23ms, mfu 2.65%\n",
            "iter 3840: loss 0.3215, time 174.72ms, mfu 2.67%\n",
            "iter 3850: loss 0.3093, time 176.42ms, mfu 2.68%\n",
            "iter 3860: loss 0.3290, time 175.38ms, mfu 2.69%\n",
            "iter 3870: loss 0.3331, time 176.72ms, mfu 2.70%\n",
            "iter 3880: loss 0.2962, time 176.16ms, mfu 2.71%\n",
            "iter 3890: loss 0.3286, time 175.29ms, mfu 2.72%\n",
            "iter 3900: loss 0.3382, time 176.52ms, mfu 2.72%\n",
            "iter 3910: loss 0.3035, time 177.44ms, mfu 2.73%\n",
            "iter 3920: loss 0.3087, time 176.39ms, mfu 2.73%\n",
            "iter 3930: loss 0.3187, time 175.98ms, mfu 2.74%\n",
            "iter 3940: loss 0.3148, time 175.01ms, mfu 2.74%\n",
            "iter 3950: loss 0.3266, time 176.72ms, mfu 2.75%\n",
            "iter 3960: loss 0.3126, time 176.21ms, mfu 2.75%\n",
            "iter 3970: loss 0.3391, time 175.52ms, mfu 2.75%\n",
            "iter 3980: loss 0.3196, time 175.98ms, mfu 2.76%\n",
            "iter 3990: loss 0.3253, time 175.78ms, mfu 2.76%\n",
            "step 4000: train loss 0.1191, val loss 11.5334\n",
            "iter 4000: loss 0.3120, time 24488.67ms, mfu 2.49%\n",
            "iter 4010: loss 0.3193, time 178.10ms, mfu 2.51%\n",
            "iter 4020: loss 0.3205, time 176.14ms, mfu 2.54%\n",
            "iter 4030: loss 0.3190, time 176.92ms, mfu 2.56%\n",
            "iter 4040: loss 0.3082, time 177.68ms, mfu 2.58%\n",
            "iter 4050: loss 0.3114, time 175.71ms, mfu 2.60%\n",
            "iter 4060: loss 0.2966, time 174.91ms, mfu 2.62%\n",
            "iter 4070: loss 0.3060, time 177.33ms, mfu 2.64%\n",
            "iter 4080: loss 0.3222, time 174.39ms, mfu 2.66%\n",
            "iter 4090: loss 0.3144, time 175.01ms, mfu 2.67%\n",
            "iter 4100: loss 0.3033, time 178.24ms, mfu 2.68%\n",
            "iter 4110: loss 0.2980, time 175.98ms, mfu 2.69%\n",
            "iter 4120: loss 0.2621, time 174.96ms, mfu 2.70%\n",
            "iter 4130: loss 0.3026, time 175.41ms, mfu 2.71%\n",
            "iter 4140: loss 0.3236, time 175.56ms, mfu 2.72%\n",
            "iter 4150: loss 0.2699, time 175.56ms, mfu 2.73%\n",
            "iter 4160: loss 0.2919, time 176.57ms, mfu 2.73%\n",
            "iter 4170: loss 0.2805, time 175.06ms, mfu 2.74%\n",
            "iter 4180: loss 0.3003, time 176.11ms, mfu 2.74%\n",
            "iter 4190: loss 0.2998, time 175.64ms, mfu 2.75%\n",
            "iter 4200: loss 0.2895, time 176.88ms, mfu 2.75%\n",
            "iter 4210: loss 0.3015, time 176.68ms, mfu 2.75%\n",
            "iter 4220: loss 0.2911, time 176.02ms, mfu 2.76%\n",
            "iter 4230: loss 0.2974, time 175.39ms, mfu 2.76%\n",
            "iter 4240: loss 0.2974, time 174.72ms, mfu 2.76%\n",
            "step 4250: train loss 0.1129, val loss 11.5932\n",
            "iter 4250: loss 0.2872, time 24495.09ms, mfu 2.49%\n",
            "iter 4260: loss 0.2923, time 176.97ms, mfu 2.52%\n",
            "iter 4270: loss 0.2949, time 177.25ms, mfu 2.54%\n",
            "iter 4280: loss 0.3002, time 175.95ms, mfu 2.57%\n",
            "iter 4290: loss 0.2659, time 176.10ms, mfu 2.59%\n",
            "iter 4300: loss 0.2809, time 175.09ms, mfu 2.61%\n",
            "iter 4310: loss 0.2786, time 176.57ms, mfu 2.63%\n",
            "iter 4320: loss 0.2842, time 175.95ms, mfu 2.64%\n",
            "iter 4330: loss 0.2838, time 175.59ms, mfu 2.66%\n",
            "iter 4340: loss 0.2699, time 175.66ms, mfu 2.67%\n",
            "iter 4350: loss 0.2736, time 176.46ms, mfu 2.68%\n",
            "iter 4360: loss 0.2909, time 174.92ms, mfu 2.69%\n",
            "iter 4370: loss 0.2845, time 176.15ms, mfu 2.70%\n",
            "iter 4380: loss 0.2774, time 175.80ms, mfu 2.71%\n",
            "iter 4390: loss 0.2973, time 175.82ms, mfu 2.72%\n",
            "iter 4400: loss 0.2798, time 175.84ms, mfu 2.73%\n",
            "iter 4410: loss 0.2826, time 175.18ms, mfu 2.73%\n",
            "iter 4420: loss 0.3069, time 176.91ms, mfu 2.74%\n",
            "iter 4430: loss 0.2966, time 176.85ms, mfu 2.74%\n",
            "iter 4440: loss 0.2918, time 176.89ms, mfu 2.74%\n",
            "iter 4450: loss 0.2688, time 176.09ms, mfu 2.75%\n",
            "iter 4460: loss 0.2761, time 176.01ms, mfu 2.75%\n",
            "iter 4470: loss 0.2731, time 175.29ms, mfu 2.76%\n",
            "iter 4480: loss 0.2679, time 175.16ms, mfu 2.76%\n",
            "iter 4490: loss 0.2408, time 176.47ms, mfu 2.76%\n",
            "step 4500: train loss 0.1072, val loss 11.6523\n",
            "iter 4500: loss 0.2663, time 24500.10ms, mfu 2.49%\n",
            "iter 4510: loss 0.2549, time 176.04ms, mfu 2.52%\n",
            "iter 4520: loss 0.2790, time 176.19ms, mfu 2.54%\n",
            "iter 4530: loss 0.2742, time 176.20ms, mfu 2.57%\n",
            "iter 4540: loss 0.2858, time 176.48ms, mfu 2.59%\n",
            "iter 4550: loss 0.3080, time 175.78ms, mfu 2.61%\n",
            "iter 4560: loss 0.2675, time 174.39ms, mfu 2.63%\n",
            "iter 4570: loss 0.2845, time 176.93ms, mfu 2.64%\n",
            "iter 4580: loss 0.2675, time 174.64ms, mfu 2.66%\n",
            "iter 4590: loss 0.2764, time 175.97ms, mfu 2.67%\n",
            "iter 4600: loss 0.2736, time 175.10ms, mfu 2.68%\n",
            "iter 4610: loss 0.2476, time 174.96ms, mfu 2.70%\n",
            "iter 4620: loss 0.2727, time 174.76ms, mfu 2.71%\n",
            "iter 4630: loss 0.2857, time 178.35ms, mfu 2.71%\n",
            "iter 4640: loss 0.2585, time 174.75ms, mfu 2.72%\n",
            "iter 4650: loss 0.2756, time 174.58ms, mfu 2.73%\n",
            "iter 4660: loss 0.2647, time 174.76ms, mfu 2.74%\n",
            "iter 4670: loss 0.2572, time 175.84ms, mfu 2.74%\n",
            "iter 4680: loss 0.2609, time 177.84ms, mfu 2.74%\n",
            "iter 4690: loss 0.2755, time 175.70ms, mfu 2.75%\n",
            "iter 4700: loss 0.2731, time 176.33ms, mfu 2.75%\n",
            "iter 4710: loss 0.2727, time 175.77ms, mfu 2.76%\n",
            "iter 4720: loss 0.2691, time 176.94ms, mfu 2.76%\n",
            "iter 4730: loss 0.2634, time 176.05ms, mfu 2.76%\n",
            "iter 4740: loss 0.2689, time 175.76ms, mfu 2.76%\n",
            "step 4750: train loss 0.1053, val loss 11.7220\n",
            "iter 4750: loss 0.2632, time 24480.53ms, mfu 2.49%\n",
            "iter 4760: loss 0.2608, time 176.79ms, mfu 2.52%\n",
            "iter 4770: loss 0.2682, time 177.36ms, mfu 2.54%\n",
            "iter 4780: loss 0.2684, time 175.19ms, mfu 2.57%\n",
            "iter 4790: loss 0.2588, time 176.20ms, mfu 2.59%\n",
            "iter 4800: loss 0.2603, time 175.81ms, mfu 2.61%\n",
            "iter 4810: loss 0.2735, time 176.43ms, mfu 2.63%\n",
            "iter 4820: loss 0.2577, time 176.88ms, mfu 2.64%\n",
            "iter 4830: loss 0.2460, time 177.30ms, mfu 2.65%\n",
            "iter 4840: loss 0.2663, time 174.83ms, mfu 2.67%\n",
            "iter 4850: loss 0.2827, time 176.66ms, mfu 2.68%\n",
            "iter 4860: loss 0.2527, time 175.65ms, mfu 2.69%\n",
            "iter 4870: loss 0.2810, time 175.64ms, mfu 2.70%\n",
            "iter 4880: loss 0.2483, time 178.01ms, mfu 2.71%\n",
            "iter 4890: loss 0.2431, time 175.15ms, mfu 2.71%\n",
            "iter 4900: loss 0.2608, time 175.32ms, mfu 2.72%\n",
            "iter 4910: loss 0.2619, time 175.13ms, mfu 2.73%\n",
            "iter 4920: loss 0.2604, time 176.86ms, mfu 2.73%\n",
            "iter 4930: loss 0.2581, time 176.66ms, mfu 2.74%\n",
            "iter 4940: loss 0.2493, time 176.56ms, mfu 2.74%\n",
            "iter 4950: loss 0.2634, time 175.72ms, mfu 2.75%\n",
            "iter 4960: loss 0.2329, time 175.52ms, mfu 2.75%\n",
            "iter 4970: loss 0.2464, time 177.46ms, mfu 2.75%\n",
            "iter 4980: loss 0.2553, time 176.43ms, mfu 2.76%\n",
            "iter 4990: loss 0.2498, time 177.00ms, mfu 2.76%\n",
            "step 5000: train loss 0.1021, val loss 11.7434\n",
            "iter 5000: loss 0.2632, time 24493.72ms, mfu 2.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sample.py --out_dir=out-poetry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr4H0fU1ffdu",
        "outputId": "33c31e11-9730-43a0-b7f3-db7f919beb0e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding: out_dir = out-poetry\n",
            "number of parameters: 29.94M\n",
            "No meta.pkl found, assuming GPT-2 encodings...\n",
            "\n",
            " \n",
            "Mame down like a matter we were not so much to want for a heart. And,\n",
            " \n",
            "I was no longer again?\n",
            "I cannot kill what had an accessory.\n",
            "I have. I’t visit the sky.\n",
            "and who see me.\n",
            "and they knew\n",
            "in a man to look with the dead.\n",
            "I knew it is the long\n",
            " \n",
            " \n",
            " \n",
            "I didn’s the bed.\n",
            "in my life\n",
            " \n",
            "You don’s pure to say. I have seen\n",
            " \n",
            "I was a kind of a harness to be a lie like a thing\n",
            " \n",
            "I had taken\n",
            "Mimself.\n",
            " \n",
            "I don’t know\n",
            "or the dark,\n",
            " \n",
            "Unit has been still say.\n",
            "My room.\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Your heart\n",
            " \n",
            "and, a father”\n",
            "Let me.\n",
            "I don’s not a wheelchair away.\n",
            "I was the edge of us.\n",
            " \n",
            " \n",
            " \n",
            "Some lover has left the table.\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "They could have a boy and I go in a river:\n",
            " \n",
            " \n",
            " \n",
            "That\n",
            " \n",
            "I don’t get\n",
            " \n",
            "I am it.\n",
            " \n",
            " \n",
            "But it more.\n",
            " \n",
            "on a window and be a girl’s\n",
            "I don’s human child,\n",
            "When all my head.\n",
            " \n",
            " \n",
            "who swung the dead.\n",
            "We heard the open.\n",
            "to a poem.\n",
            "I do not done here.\n",
            " \n",
            "I I was a place.\n",
            " \n",
            "My economy is the forest of his blood.\n",
            "I was the world but ever’ve been on the wind in a fire\n",
            "My economy is not, my mother, you can say, a house.\n",
            "which I have this way.\n",
            " \n",
            "On my face, then in my sense.\n",
            "As for ourselves.\n",
            "not a place.\n",
            " \n",
            "I”\n",
            "”\n",
            "The sense of a little dream one will be given.\n",
            "The time.\n",
            " \n",
            "Our kut unta man.\n",
            "2.\n",
            "When I think of a few have known.\n",
            "And I was the eyes in each other.\n",
            "And the word in the face,’s all around the wall\n",
            " \n",
            "The few more than\n",
            "---------------\n",
            "\n",
            "into the river is more died.\n",
            "The sky.\n",
            " \n",
            "Here, and.\n",
            " \n",
            "The Pacific, the same,\n",
            "I could make other, a poem,\n",
            "She could\n",
            "And so, let the same time.\n",
            "But I, I am going the streets.\n",
            "I wish. The angel in a word, in the right to survive, and love, the story was the first just\n",
            "and\n",
            " \n",
            "I had been, to its mind,\n",
            "My economy is\n",
            " The light. The wall\n",
            "The little wife can have been now,\n",
            " \n",
            " And the earth. You may come.\n",
            " \n",
            "I must help that:\n",
            "I once.\n",
            "My woman is a single tree,\n",
            " \n",
            " \n",
            "I was\n",
            " \n",
            "and live on the water between the sun.\n",
            "When’toward the wind.\n",
            "My chest. \"They are alone,\n",
            "The street—I think this kid and we were my hands say,\n",
            "This was a miracle, if it? I say,\n",
            " \n",
            "Or they are,\n",
            " \n",
            "for a whole life,\n",
            "The wall, one's fallen\n",
            "But the couch\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "I have worse\n",
            "I am for the way to read the wood. But the airport, now how the wind. \n",
            "Then as a voice\n",
            " \n",
            "I might have to her words.\n",
            " \n",
            "I have taken his ground.\n",
            " \n",
            "They could not a screen\n",
            "My wife became your heart.\n",
            "And the airport, like a kind of the day on the darkly high school and white, I was. Look in three years.\n",
            "In the ground.\n",
            "his hand,\n",
            "My mother.\n",
            " \n",
            " \n",
            "When a single-water man becomes in the city.\n",
            " \n",
            "For the lucky side of the man that I want the river.\n",
            " \n",
            " \n",
            "A man than my back.\n",
            "who told you say\n",
            "And any more than the day.\n",
            " \n",
            "This is the color.\n",
            "I cried it.\n",
            "There’s the end.\n",
            " \n",
            "And all the ocean.\n",
            "I'm like a second\n",
            "s.\n",
            "Steance, the man and that, the world in the moment.\n",
            "The time.\n",
            "That's not a pounds in the world. I am not the way to your, I can,\n",
            "I would be this. Childhood\n",
            "I want me,\n",
            "---------------\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "my face\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "and how\n",
            "and others\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "you are\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "hault back the company.\n",
            " \n",
            " \n",
            "open to take a corner like the leaves\n",
            " \n",
            " \n",
            " \n",
            "becagace were\n",
            "and a fear\n",
            " \n",
            " \n",
            "Daginary eyes\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "jagged\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "no ma\n",
            " \n",
            " \n",
            "Imaginary other\n",
            "to the earth\n",
            " \n",
            " \n",
            "Imended\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "in the other\n",
            "orove a lake\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "I didn’s\n",
            " \n",
            " \n",
            " •\n",
            "a katts slaught then grow\n",
            " \n",
            "by the gate\n",
            " \n",
            " \n",
            "how are not an\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "I took your\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "this\n",
            " \n",
            " \n",
            " \n",
            "he said,\n",
            "i-bant\n",
            "but my mouth\n",
            " \n",
            "and the kitchen\n",
            " \n",
            " \n",
            "to my children would be in the same\n",
            " \n",
            "he has be up the words\n",
            "the people where your\n",
            "as the beauty\n",
            " \n",
            " \n",
            "you are done\n",
            "I’s a few day\n",
            " \n",
            " \n",
            " \n",
            "i/\n",
            "my mouth of a pishno ma\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "wied the sun\n",
            " \n",
            " \n",
            "of a farmer\n",
            "areomewal\n",
            " \n",
            " \n",
            " \n",
            "over the night\n",
            " \n",
            "through the same sames its own cause be your mouth.\n",
            "the boy\n",
            "I got the heat of her\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "of a way.\n",
            "They shall be with the same day \n",
            " \n",
            " \n",
            " \n",
            "wil.\n",
            " \n",
            "a green people won't open\n",
            " \n",
            "Imag chips.\n",
            " \n",
            " \n",
            " \n",
            "have the same\n",
            " \n",
            " \n",
            "and the\n",
            "---------------\n",
            "\n",
            "like a way at a time,\n",
            "by a little a poem\n",
            " \n",
            "I was the same way to the\n",
            "After this?\n",
            "Like the sun.\n",
            "I have\n",
            "The possic\n",
            " \n",
            "I have changed from the wind\n",
            " \n",
            " \n",
            "And the distance.\n",
            "This is no longer with that that will be a�s.\n",
            "And we,\n",
            "To keep the moon.\n",
            "They might have a man.\n",
            "I would come.\n",
            " \n",
            "We am never know that,\n",
            " \n",
            "Who could go up.\n",
            "And I am a great man was lit a foreign fire from it,\n",
            "The mother,\n",
            "And a place,\n",
            "The storm-we have been buried.\n",
            "When I am the blood of the world.\n",
            "From the roof.\n",
            "has a long, I've been a white.\n",
            "I was forgotten that were crossed off my mother.\n",
            "You are.\n",
            "And an next one a man.\n",
            "and often.\n",
            "They are through the streets.\n",
            "My own\n",
            " \n",
            "A woman's a great\n",
            " \n",
            "A voice.\n",
            "I am in the last day, a gayles.\n",
            "And a house,\n",
            "To carry a need to connect\n",
            "And the forest of that, I say,\n",
            "and the world.\n",
            "is, like a hole,\n",
            " \n",
            " \n",
            "They will have more true\n",
            "Her white-door-out of customs offerings in the chair,\n",
            "And the last light of the dark.\n",
            "And I see it.\n",
            "No one to the gung to knowing their sense, I am not even with its mother.\n",
            "From the way it.\n",
            "My economy is a bullet.\n",
            "by the light of the light. I have been.\n",
            "There was something. \n",
            "without a miracle and in the face,\n",
            "And the gate of my hand.\n",
            "And a river,\n",
            " \n",
            "on a long.\n",
            "And when my neck on a�t a woman.\n",
            " The single years of the heart.\n",
            "I want to the sky.\n",
            "You look at one side.\n",
            "I came to me, a man looks from the key,\n",
            "And it.\n",
            "The other, saying.\n",
            "They carried my fear.\n",
            "I put my name of the summer of the hills, now, our own.\n",
            "nor.\n",
            "with every world is the same day is the wall.\n",
            "You are a sign for the summer; my garden after the cold.\n",
            "and the ground\n",
            "---------------\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "I want to me\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "The day.\n",
            " \n",
            " \n",
            " \n",
            "gaginary cames the day\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "as the wind\n",
            "of kut unta great kisses\n",
            "a kut unta putath the ground\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "the cold green\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "It was the snow\n",
            "a sun\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "A falnishno ma\n",
            " \n",
            "I can mean is not an nung\n",
            " \n",
            "V Same in a bullet\n",
            " \n",
            "is a pishno ma\n",
            " \n",
            " \n",
            " \n",
            "We has not the other ago\n",
            " \n",
            " \n",
            " \n",
            "his name\n",
            " \n",
            " \n",
            " \n",
            "The farmer with my plastic\n",
            " \n",
            " \n",
            " \n",
            "I remember i'd have ever have kicked my eyes\n",
            "the long\n",
            " \n",
            " \n",
            " \n",
            "the whole\n",
            " \n",
            " \n",
            "stove I am almost ever\n",
            " \n",
            "and the air\n",
            "She rounds the world had a bright thousand years.\n",
            "no ma\n",
            "Let me\n",
            "from the room\n",
            "Not a wall at the blood of the river who are a long words\n",
            " \n",
            " \n",
            "a ficked these way around the same air\n",
            "And the dry air.\n",
            " \n",
            " \n",
            "Imaginary night the same wind\n",
            "the fire\n",
            " \n",
            "From life with a boy,\n",
            " \n",
            "the least that time of blue space on\n",
            "I've been at your eyes\n",
            "the same one\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\"stared down\n",
            "They were\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "I want the moon\n",
            " \n",
            "I take in the next room\n",
            "the river.\n",
            " \n",
            "To be around my head across the door. \n",
            " \n",
            " \n",
            "On the space,\n",
            " \n",
            "and in you that, a world under the north time.\n",
            "A stranger turned into the body had to take your mother might be let the sound\n",
            " \n",
            " \n",
            "in the ground of your heads.\n",
            " \n",
            "of the sun\n",
            "that asks the man a man.\n",
            "He is too much of us,\n",
            " \n",
            "I know the way to the morning\n",
            " \n",
            "\n",
            "---------------\n",
            "\n",
            "What you you you.\n",
            "They are my left them understand you.\n",
            "I die.\n",
            "From the way to me but explain how anyone the world\n",
            "But you are you are a house.\n",
            " \n",
            " \n",
            " \n",
            "And it\n",
            "Two end.\n",
            " \n",
            "under the world.\n",
            "The men.\n",
            " \n",
            " \n",
            "Your sister’s nothing so. The poem\n",
            "The clothes in your life\n",
            " \n",
            "My economy is the world's not a house,\n",
            "The age.\n",
            "She is true\n",
            "You’s of the world, the grass.\n",
            "A economy is the room.\n",
            "A father’s a moment\n",
            "I\n",
            "I was going to the floor.\n",
            "You’t use that\n",
            "and the ground\n",
            " \n",
            "He asked\n",
            "You'd take a girl I call it is a photament\n",
            "And it is so, I.\n",
            "My economy's long\n",
            "I will hold you\n",
            "In the world with a prophet's free,\n",
            " \n",
            "I did not with your bed.\n",
            "What was a broken\n",
            " \n",
            "I do\n",
            " \n",
            "All night.\n",
            " \n",
            "As I know I’s that was a man's\n",
            "And it, nothing.\n",
            "To make of the word,\n",
            "And I thought when you know\n",
            "When I will become my fear of silence.\n",
            "I can be it says,\n",
            "And you. It’s a book.\n",
            " \n",
            " \n",
            "The boy. \n",
            "How much be said. A bumbling of my mouth, like the time to you remember.\n",
            "The one\n",
            " \n",
            "Yet one means a wall.\n",
            "I're like the water.\n",
            "I carried my mother is not to your mouth.\n",
            "I die.\n",
            " \n",
            " \n",
            "But when I had a human.\n",
            "You, waiting to the air into all his sense of your children, and I love your mother's the edge of everything.\n",
            "His economy is a kind of the night, I can I am here.\n",
            "To kill me like a little world.\n",
            "A mother have to the blood of me.\n",
            "The hole of\n",
            "The little two days a long of white.\n",
            "In the most been a person of a kind of the animals.\n",
            "Maybe she.\n",
            "When I’s to the world.\n",
            "The other.\n",
            "That is nothing to leave you to sleep.\n",
            "and of my mother has changed.\n",
            "The house:\n",
            "I’t so much of\n",
            "---------------\n",
            "\n",
            "on which the end of the truck on the fire\n",
            "when the light\n",
            "the least on the bucket of the sense of the beginning the river of the same grass.\n",
            "The other\n",
            " \n",
            " \n",
            "his husband-eye-down to me\n",
            "caying\n",
            "and sludge the other light and the world;\n",
            "an blue\n",
            " \n",
            "and the man that I call it is with the distance,\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "this way of it.\n",
            " \n",
            " \n",
            " \n",
            "And the sea\n",
            " \n",
            "and I hadn't come from her fear of the real men\n",
            "and the sound. And she would have been a time\n",
            " \n",
            "and the one\n",
            "my men\n",
            " \n",
            " \n",
            "but not\n",
            "to give the world\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "and the street\n",
            " \n",
            "is up and the dead\n",
            "She are\n",
            "Let him.\n",
            " \n",
            " \n",
            "I was just the next one.\n",
            "that was a love the stone he slips only think when it,\n",
            " \n",
            " \n",
            "There, and smell a fire\n",
            " \n",
            " \n",
            " \n",
            "the good you that would add a box of the sound of a world,\n",
            "the wind.\n",
            "the boy can have no longer\n",
            "All night.\n",
            "by the hills.\n",
            " \n",
            "of my whole deer and the country,\n",
            "When we call it. But the wind of the end of another\n",
            "I wish I imagine it is a sound of it was the mountain\n",
            "but even say my tongue a light and the deep forward.\n",
            " \n",
            "I wanted to a way with being a sheet of a little family\n",
            " \n",
            " \n",
            "and the surface\n",
            " \n",
            " \n",
            " \n",
            "Do you and of least it,\n",
            "All night, the season.\n",
            " \n",
            " \n",
            "now night in a boy with your words\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Where it where you’s in the world”\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "we have been eaten me, it\n",
            " \n",
            " \n",
            "Hangled on the sun.\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "The fire into a great dog pue-\n",
            "but you do you to rise itself\n",
            "I can be done to the world who’t think you\n",
            "I will die.\n",
            "What is the sea.\n",
            " \n",
            " \n",
            "an\n",
            "---------------\n",
            "\n",
            "Simit's he hears me.\n",
            " \n",
            " \n",
            " \n",
            "one man,\n",
            " \n",
            " \n",
            "—the night,\n",
            " \n",
            "But I was poisoned\n",
            "No longer, be a field.\n",
            "Let the ground\n",
            " \n",
            " \n",
            "I look to what is the dead\n",
            "fove of his girls\n",
            "its house,\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "A face\n",
            "you're not the sun's a sheet\n",
            " \n",
            "This is a human mother\n",
            "Hreata rose,\n",
            " \n",
            " \n",
            "of his face\n",
            "Such were like a two day.\n",
            " \n",
            " \n",
            " \n",
            "My economy is not\n",
            " \n",
            "She works a poem,\n",
            " \n",
            " \n",
            " \n",
            "And so long, but a great\n",
            " \n",
            "a heart.\n",
            "Intus,\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "When I had been\n",
            "and you have in one\n",
            "The light\n",
            "we reach a flock of what the same week,\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "the dark\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "I.\n",
            "and did not the middle of love\n",
            "The poet's black\n",
            "I see the river\n",
            " \n",
            "cearing a great family\n",
            "so are the way of the eye of a man and the wind,\n",
            " \n",
            " \n",
            "But the field\n",
            " \n",
            "To the same idea.\n",
            "Who were my father's lost him.\n",
            " \n",
            "And my bodies.\n",
            "The same wind of dust.\n",
            " \n",
            "It is the right.\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "and then so much more than the world,\n",
            "And a wind. The body. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "I want to speak of the song.\n",
            "To fight off.\n",
            "And all sleeping in the mountains\n",
            "He killed your breath. \n",
            "B's only, like a pack,\n",
            "The end.\n",
            "I am it open.\n",
            "The Pacific.\n",
            " \n",
            " the future, the leaves.\n",
            "that will have the glass.\n",
            "I gave the world.\n",
            "If you without\n",
            "To carry the air.\n",
            "I make of the day?\n",
            "The night,\n",
            "and quiet sky.\n",
            "My name.\n",
            " \n",
            "I keep the only.\n",
            "And he still,\n",
            "They forget the wet air.\n",
            "The face a sound.\n",
            " \n",
            "He comparing our head.\n",
            "That's my son, a time.\n",
            " \n",
            "A time\n",
            "---------------\n",
            "\n",
            " For the dry\n",
            "the night,\n",
            "the end,\n",
            "the cold\n",
            "And each window in two air\n",
            "From night\n",
            "Of day, the wrong life.\n",
            "The morning\n",
            "And death\n",
            "And of the water\n",
            "And the TV time.\n",
            "And day's\n",
            "in the time in the wall.\n",
            "The other\n",
            " \n",
            "a great man,\n",
            " \n",
            "In the grass.\n",
            "About the blood.\n",
            "And the back, who the second life,\n",
            "And the air.\n",
            "The wind\n",
            "At the gate\n",
            "And then, a man, a dog, the river.\n",
            " \n",
            "The window\n",
            " \n",
            "The other\n",
            "A kag on the light.\n",
            "He returns\n",
            "I open a body.\n",
            "And the streets.\n",
            "And the sun;\n",
            "In heaven.\n",
            "The word—\n",
            "She didn't look out the sun. The children,\n",
            "They're at night, like a glass, what does a narrative of a river,\n",
            "the old air;\n",
            "The other,\n",
            "But the smell of the sea space, that, I hear is not a life,\n",
            "and night\n",
            " \n",
            "what should see this was a wood.\n",
            "The one\n",
            "A man’s not.\n",
            "That is a fire.\n",
            "The whole room in the blue rain\n",
            "My economy has scench in.\n",
            " that,\n",
            "He returns, is the suns.\n",
            "That time,\n",
            "To me with a single idea of it\n",
            "A little body.\n",
            "And the floor,\n",
            " \n",
            "And in the city.\n",
            "With a hand on the cold.\n",
            "And would be a pretty\n",
            "When my mouth. The future,\n",
            "In a young, a family\n",
            "To be a white black\n",
            "And the wall, the sun.\n",
            "The day, the light.\n",
            ".\n",
            "The best, or his right.\n",
            "The future, perhaps,\n",
            "And the men,\n",
            "And the wall.\n",
            "And here,\n",
            "They will have put a map,\n",
            "But that that I had a place,\n",
            "a man.\n",
            "For the past,\n",
            "But you a single one of the wind.\n",
            "The one\n",
            "With a thing for you have right\n",
            "In the wall, the key,\n",
            "No dog, the one of the gate\n",
            "My economy is with a head in one\n",
            "And I am only to a new eyes too, and.\n",
            "I knew to see that, like a dog, like everything does not.\n",
            "I was an pitch to the fire\n",
            "---------------\n",
            "\n",
            "I'd have to me the sun\n",
            "To the chair\n",
            "as though I do not a sound about\n",
            "I would have passed.\n",
            "I still like a place.\n",
            " \n",
            " \n",
            "I are then\n",
            " \n",
            "You a child’s just so the table\n",
            "To be\n",
            "You have you are an blood\n",
            "It’s.\n",
            "It’s eye.\n",
            "I’t cry.\n",
            "And he taught me,\n",
            "I want to you a man or all.\n",
            "My economy is the world?\n",
            "I was never find my mother was a world in this poems to another.\n",
            "’m ours.\n",
            "The man with a\n",
            "A poem.\n",
            "When I was a poem?\n",
            " \n",
            "So she is the world.\n",
            "To keep the cold and explain you\n",
            "The wind.\n",
            "And some Monday.\n",
            "through which he could stop.\n",
            "As full window.\n",
            " \n",
            "Because a place,\n",
            " \n",
            "But though the story.\n",
            "Did you to\n",
            "And how he want to the same less he was a field so Serious.\n",
            "Which economy has a economy is two\n",
            " \n",
            "I could you can do not a long. I have no longer\n",
            "The fear of the wound.\n",
            "I’s going.\n",
            "The fire.\n",
            "and all one\n",
            "I want me you you only.\n",
            " \n",
            "We may said:\n",
            "She asks the awe.\n",
            "Fver\n",
            "that was a child’t know for the page,\n",
            "And the world I have given you’t,\n",
            "A pOUSur, the table.\n",
            "And you know\n",
            "And you wish would make out a child.\n",
            "is no say when your mother.\n",
            " \n",
            "You’t explain, I be this world would the meaning of a time.\n",
            "My economy is a kind of the skin the table.\n",
            " \n",
            "The kid.\n",
            "And the inside the garden look when I know.\n",
            "A room.\n",
            "I know you a moment.\n",
            "And the sun.\n",
            "Can a lot.\n",
            "To call the wind.\n",
            "I have always a long, of the deep\n",
            " \n",
            " \n",
            "Her dreams in the same.\n",
            "And you\n",
            "And he was like an last\n",
            "You can’t able to know I set your desire. Why know.\n",
            "My economy is a river.\n",
            "And you,\n",
            " \n",
            "I was never be\n",
            "It is the world on the sun.\n",
            "She is still.\n",
            "---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%autosave 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_DFItjF60nQ5",
        "outputId": "814a9224-ac18-416d-8478-487866afe352"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ]
    }
  ]
}